# -*- coding: utf-8 -*-
"""google_crawling.ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/1QiqVKw1e_XePmB1xuwpWcUH4H-aCuJVg
"""

# Commented out IPython magic to ensure Python compatibility.
#기본적으로 필요한 라이브러리
import numpy as np
import pandas as pd
# %config IPCompleter.greedy=True
import requests
import selenium

from selenium import webdriver
from selenium.webdriver.common.keys import Keys
import time
from bs4 import BeautifulSoup

options = webdriver.ChromeOptions()
#options.add_argument('headless')    # 웹 브라우저를 띄우지 않는 headless chrome 옵션 적용
#options.add_argument('disable-gpu')    # GPU 사용 안함
options.add_argument('lang=ko_KR')    # 언어 설정
driver = webdriver.Chrome("chromedriver", options=options) #  옵션 적용

import os

path_dir = 'C:/Users/user/OneDrive - 이화여자대학교/3-1/05 파이썬과데이터분석'
#csv파일이 있는 폴더 경로 입력

for dirname, _, filenames in os.walk(path_dir):
    for filename in filenames:
        print(os.path.join(dirname, filename))

seoul_rest = pd.read_csv("C:/Users/user/OneDrive - 이화여자대학교/3-1/05 파이썬과데이터분석/seoul_restaurants.csv", encoding='cp949')
#encoding은 한글을 읽기 위한 인코딩

seoul_rest.head()

seoul_rest.dtypes

seoul_rest = seoul_rest[['상세영업상태코드','전화번호','도로명주소','사업장명','업태구분명']]

seoul_rest.head()

seoul_rest = seoul_rest[seoul_rest.상세영업상태코드 == 1]

seoul_rest.head(10)

seoul_rest.업태구분명.unique()

pip install selenium

import requests
import selenium

from selenium import webdriver
from selenium.webdriver.common.keys import Keys
import time
from bs4 import BeautifulSoup

options = webdriver.ChromeOptions()
#options.add_argument('headless')    # 웹 브라우저를 띄우지 않는 headless chrome 옵션 적용
#options.add_argument('disable-gpu')    # GPU 사용 안함
options.add_argument('lang=ko_KR')    # 언어 설정
driver = webdriver.Chrome("chromedriver", options=options) #  옵션 적용


driver.get("https://www.google.co.kr/maps/")
#검색할 검색엔지 url 입력

driver = webdriver.Chrome("chromedriver", options=options) #  옵션 적용
driver.get("https://www.google.co.kr/maps/")

# 검색창 찾아서 검색어 입력 실험하는 블럭
search_box = driver.find_element_by_id("searchboxinput")
search_box.clear()
search_box.send_keys("위샐러듀 서대문구")
search_box.send_keys(Keys.ENTER)

time.sleep(1)

# 리뷰창 클릭
driver.find_element_by_xpath('//*[@id="pane"]/div/div[1]/div/div/div[2]/div[1]/div[1]/div[2]/div/div[1]/span[1]/span/span/span[2]/span[1]/button').click()

# 별점 갖고 오는 거 실험
review_star = driver.find_elements_by_class_name("ODSEW-ShBeI-content")

star = []
for i in range(len(review_star)):
    a = review_star[i].find_element_by_class_name("ODSEW-ShBeI-H1e3jb").get_attribute("aria-label")
    print(type(a))
    star.append(a)
    
star

# 리뷰 본문 갖고 오는 거 실험
review_list = driver.find_elements_by_class_name("ODSEW-ShBeI-content")
for i in range(len(review_list)):
        review_text = review_list[i].find_element_by_class_name("ODSEW-ShBeI-RgZmSc-date").text
        print(type(review_text))

# 검색부터 리뷰 창 들어가기 및 별점/날짜/본문까지 한꺼번에 갖고 오는 거 실험
driver.get("https://www.google.co.kr/maps/")
search_box = driver.find_element_by_id("searchboxinput")
search_box.clear()
search_box.send_keys("위샐러듀 서대문구")
search_box.send_keys(Keys.ENTER)

time.sleep(2)

driver.find_element_by_xpath('//*[@id="pane"]/div/div[1]/div/div/div[2]/div[1]/div[1]/div[2]/div/div[1]/span[1]/span/span/span[2]/span[1]/button').click()

time.sleep(1)

review_list = driver.find_elements_by_class_name("ODSEW-ShBeI-content")
result = []
for i in range(len(review_list)):
    review_star = review_list[i].find_element_by_class_name("ODSEW-ShBeI-H1e3jb").get_attribute("aria-label")
    review_text = review_list[i].find_element_by_class_name("ODSEW-ShBeI-text").text
    review_date = review_list[i].find_element_by_class_name("ODSEW-ShBeI-RgZmSc-date").text
    print(review_star,review_text,review_date)

review_list = driver.find_elements_by_class_name("ODSEW-ShBeI-content")
result = []
for i in range(len(review_list)):
    review_star = review_list[i].find_element_by_class_name("ODSEW-ShBeI-H1e3jb").get_attribute("aria-label")
    review_text = review_list[i].find_element_by_class_name("ODSEW-ShBeI-text").text
    review_date = review_list[i].find_element_by_class_name("ODSEW-ShBeI-RgZmSc-date").text
    line = [review_star,review_text,review_date]
    result.append(line)
        
result

# 리뷰창 무한 스크롤 코드
prev_height = driver.execute_script(
    "return document.querySelector('#pane > div > div.Yr7JMd-pane-content.cYB2Ge-oHo7ed > div > div > div.siAUzd-neVct.section-scrollbox.cYB2Ge-oHo7ed.cYB2Ge-ti6hGc').scrollHeight")
scroll = driver.find_element_by_class_name("section-scrollbox")
time.sleep(1)

while True:
    driver.execute_script('arguments[0].scrollBy(0,{});'.format(prev_height), scroll)
    time.sleep(2)
    curr_height = driver.execute_script(
    "return document.querySelector('#pane > div > div.Yr7JMd-pane-content.cYB2Ge-oHo7ed > div > div > div.siAUzd-neVct.section-scrollbox.cYB2Ge-oHo7ed.cYB2Ge-ti6hGc').scrollHeight")
    
    if(curr_height == prev_height):
        break
    else:
        prev_height = curr_height

# 위에 있는 거 다 합친 코드
# 크롬창을 실행하는 함수 안에 넣어서 쓰는 용임 크롬창이 띄어져 있어야 사용 가능
def get_review_data(name): # name 은 검색어
    #driver = webdriver.Chrome("chromedriver", options=options) #  옵션 적용
    #driver.get("https://www.google.co.kr/maps/")
    time.sleep(1)
    search_box = driver.find_element_by_id("searchboxinput")
    search_box.clear()
    search_box.send_keys(name)
    search_box.send_keys(Keys.ENTER)

    time.sleep(3)
    
    try:
        driver.find_element_by_xpath('//*[@id="pane"]/div/div[1]/div/div/div[2]/div[1]/div[1]/div[2]/div/div[1]/span[1]/span/span/span[2]/span[1]/button').click()
    except:
        result = '검색 결과 없음'
        return result

    time.sleep(1)
    
    prev_height = driver.execute_script(
        "return document.querySelector('#pane > div > div.Yr7JMd-pane-content.cYB2Ge-oHo7ed > div > div > div.siAUzd-neVct.section-scrollbox.cYB2Ge-oHo7ed.cYB2Ge-ti6hGc').scrollHeight")
    scroll = driver.find_element_by_class_name("section-scrollbox")
    time.sleep(1)

    while True:
        driver.execute_script('arguments[0].scrollBy(0,{});'.format(prev_height), scroll)
        time.sleep(2)
        curr_height = driver.execute_script(
            "return document.querySelector('#pane > div > div.Yr7JMd-pane-content.cYB2Ge-oHo7ed > div > div > div.siAUzd-neVct.section-scrollbox.cYB2Ge-oHo7ed.cYB2Ge-ti6hGc').scrollHeight")
    
        if(curr_height == prev_height):
            break
        else:
            prev_height = curr_height
    
    time.sleep(2)   
    review_list = driver.find_elements_by_class_name("ODSEW-ShBeI-content")
    result = []
           
    for i in range(len(review_list)):
        review_star = review_list[i].find_element_by_class_name("ODSEW-ShBeI-H1e3jb").get_attribute("aria-label")
        #print("별점완료",i)
        review_text = review_list[i].find_element_by_class_name("ODSEW-ShBeI-text").text
        #print("리뷰완료",i)
        review_date = review_list[i].find_element_by_class_name("ODSEW-ShBeI-RgZmSc-date").text
        #print("날짜완료",i)
        line = review_star+'|'+review_date+'|'+review_text
        #print("수집완료",i)
        result.append(line)
        
    return result

driver.close()

driver = webdriver.Chrome("chromedriver", options=options) #  옵션 적용
driver.get("https://www.google.co.kr/maps/")
get_review_data("만당회")

# 이건 csv 파일에서 식당 이름 및 주소를 뽑아내기 위한 코드
seoul_rest_names = seoul_rest.사업장명.values[:]
address = seoul_rest[seoul_rest['사업장명'] == seoul_rest_names[0]].도로명주소.values[0]
len(seoul_rest_names)

# 모두 합친 거
import requests
import selenium

from selenium import webdriver
from selenium.webdriver.common.keys import Keys
import time
from bs4 import BeautifulSoup

options = webdriver.ChromeOptions()
#options.add_argument('headless')    # 웹 브라우저를 띄우지 않는 headless chrome 옵션 적용
#options.add_argument('disable-gpu')    # GPU 사용 안함
options.add_argument('lang=ko_KR')    # 언어 설정
driver = webdriver.Chrome("chromedriver", options=options) #  옵션 적용

#검색할 검색엔지 url 입력
list = seoul_rest.사업장명.values[:]
a = []
    
    
for i in range(5): # 일단은 실험용으로 5개만 했기에 len(list)로 바꿔줘야함
    name = seoul_rest.사업장명.values[i]
    address = seoul_rest[seoul_rest['사업장명'] == list[i]].도로명주소.values[0]
    driver.get("https://www.google.co.kr/maps/")
    a.append([name, get_review_data(name+address)])

driver.close()
print(a)

